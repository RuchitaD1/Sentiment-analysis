{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuchitaD1/Sentiment-analysis/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf35F-NxwKKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_corpus(corpus_path):\n",
        "  f = open(corpus_path, 'r')\n",
        "  x = f.readlines()\n",
        "  snippet2label = {}\n",
        "  for xi in x:\n",
        "    snippet, label = xi.split('\\t')\n",
        "    label = label.strip('\\n')\n",
        "    label = int(label)\n",
        "    snippet2label[snippet] = label\n",
        "  return snippet2label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyNvILau99NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23PAhUmKwwXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2l = load_corpus('trainNLP.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4B0ssKBn1Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_regex(words):\n",
        "  ret_words = []\n",
        "  for word in words:\n",
        "    if re.match(r\"^'[a-z]+\", word):\n",
        "      if re.match(r\"^'[a-z]+'$\", word):\n",
        "        ret_words.append(\"'\")\n",
        "        ret_words.append(word[1:-1])\n",
        "        ret_words.append(\"'\")\n",
        "      else:\n",
        "        ret_words.append(word)\n",
        "    elif re.match(r\"[a-z]+'$\", word):\n",
        "      ret_words.append(word[:-1])\n",
        "      ret_words.append(\"'\")\n",
        "    else:\n",
        "      ret_words.append(word)\n",
        "    \n",
        "  return ret_words\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gty2MsaToerb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(snippet):\n",
        "  words = snippet.split(' ')\n",
        "  words = split_regex(words)\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iPk6yAPo61h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tag_edits(tokenized_snippet) :\n",
        "  ret_words = [] \n",
        "  flag = 0\n",
        "  \n",
        "  for word in tokenized_snippet:\n",
        "    if flag == 1:\n",
        "      if word.endswith(\"]\"):\n",
        "        flag = 0\n",
        "        ret_words.append(\"EDIT_\"+word[:-1])\n",
        "      else:\n",
        "        ret_words.append(\"EDIT_\"+word)\n",
        "    elif word.startswith('['):\n",
        "      if word.endswith(']'):\n",
        "        ret_words.append(\"EDIT_\"+word[1:-1])\n",
        "      else:\n",
        "        flag = 1\n",
        "        ret_words.append(\"EDIT_\"+word[1:])\n",
        "    else:\n",
        "      ret_words.append(word)\n",
        "  \n",
        "    \n",
        "  return ret_words\n",
        "      \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE5Vh6jILq3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = tokenize('[a] wonderfully loopy tale of love , longing , and voting .')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAPAPt8oMR8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrw4XG0_M2RH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg = re.compile(r\"\\bnot\\b|\\bnever\\b|\\bcannot\\b|\\bno\\b|[a-z]*n't$\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd7OZeskigDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_end = [\"however\", \"but\", \"nevertheless\", \".\", \"?\", \"!\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swSGEsqKcWAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJE3rTIilYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tag_negation(tokenized_snippet):\n",
        "  global neg\n",
        "  global neg_end\n",
        "  flag = 0 \n",
        "  t_s_copy = tokenized_snippet.copy()\n",
        "  for i in range(len(t_s_copy)):\n",
        "    if t_s_copy[i].startswith(\"EDIT_\"):\n",
        "      t_s_copy[i] = t_s_copy[i][5:]\n",
        "  pos_tags = nltk.pos_tag(t_s_copy)\n",
        "\n",
        "\n",
        "  for i in range(len(pos_tags)):\n",
        "    w,t = pos_tags[i]\n",
        "    if tokenized_snippet[i] == \"EDIT_\"+w:\n",
        "      pos_tags[i] = (\"EDIT_\" + w, t)\n",
        "    if flag == 1:\n",
        "      if t == \"JJR\" or t == \"RBR\":\n",
        "        flag = 0\n",
        "      elif w in neg_end:\n",
        "        flag = 0\n",
        "      else:\n",
        "        e_w, e_t = pos_tags[i]\n",
        "        pos_tags[i] = (\"NOT_\" + e_w, e_t)\n",
        "      \n",
        "      \n",
        "    elif re.match(neg, t_s_copy[i]):\n",
        "      if t_s_copy[i] == \"not\" and t_s_copy[i+1] == \"only\":\n",
        "        flag = 0\n",
        "      else:\n",
        "        flag = 1\n",
        "  return pos_tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjWUfwN6lVYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHLhxczdliPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tokenize(\"never say never but do sometimes say not or can't\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fWUX0uHllAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "212a021a-ed4e-40b4-fa31-918365d0f750"
      },
      "source": [
        "tag_negation(a)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('never', 'RB'),\n",
              " ('NOT_say', 'VBP'),\n",
              " ('NOT_never', 'RB'),\n",
              " ('but', 'CC'),\n",
              " ('do', 'VBP'),\n",
              " ('sometimes', 'NNS'),\n",
              " ('say', 'VB'),\n",
              " ('not', 'RB'),\n",
              " ('NOT_or', 'CC'),\n",
              " (\"NOT_can't\", 'VB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE9hJ1W8axz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvTAOHDv_30y",
        "colab_type": "code",
        "outputId": "2f989e43-48ad-4b00-c593-a3d21dd74be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNWYJKTi_7hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}